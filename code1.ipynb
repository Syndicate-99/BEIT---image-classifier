{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from transformers import BeitModel, BeitConfig\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import copy\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Improved configuration with k-fold settings\n",
    "CONFIG = {\n",
    "    'data_dir': \"D:\\\\Work\\\\dont_plot_images\\\\augmented_data\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 16,\n",
    "    'num_epochs': 50,  # Reduced since we'll be training multiple times\n",
    "    'learning_rate': 0.00002,  # Reduced learning rate for more stable fine-tuning\n",
    "    'image_size': 224,\n",
    "    'beit_model': \"microsoft/beit-base-patch16-224-pt22k-ft22k\",  # Using the finetuned model\n",
    "    'use_mixed_precision': True,\n",
    "    'gradient_accumulation_steps': 2,  # Effective batch size of 16\n",
    "    'weight_decay': 0.04,  # Higher weight decay for better regularization\n",
    "    'freeze_backbone_epochs': 0,  # Don't freeze backbone to improve recall\n",
    "    'optimization_metric': 'f1_macro',  # Optimize for macro F1 score across all classes\n",
    "    'focal_loss_gamma': 3.0,  # Increased focal loss gamma to focus more on hard examples\n",
    "    'class_weights': [1.0, 0.8, 1.0, 2.0, 1.5, 2.0],  # Adjusted weights for classes with lower F1 scores\n",
    "    'augmentation_strength': 'strong',  # Stronger augmentations to improve generalization\n",
    "    'scheduler': 'cosine_warmup',  # Custom cosine scheduler with warmup\n",
    "    'use_checkpoint': False,  # Use checkpoint for model saving if available\n",
    "    'patience': 7,  # Reduced for faster training in k-fold\n",
    "    'warmup_epochs': 3,  # Reduced for faster training\n",
    "    'num_classes': 6,  # Number of classes\n",
    "    'dropout_rate': 0.3,  # Increased dropout for better regularization\n",
    "    'use_mixup': True,  # Enable mixup augmentation\n",
    "    'mixup_alpha': 0.2,  # Mixup interpolation factor\n",
    "    'use_ensemble': True,  # Use model ensemble for final predictions\n",
    "    'ensemble_epochs': [15, 20, 25, 30],  # Adjusted for shorter training\n",
    "    'use_class_balanced_loss': True,  # Use class-balanced loss\n",
    "    # K-fold specific settings\n",
    "    'k_folds': 5,          # Number of folds\n",
    "    'stratified': True,    # Whether to use stratified folds (recommended for imbalanced data)\n",
    "    'save_all_folds': True, # Whether to save models from all folds or just the best\n",
    "    'run_kfold': True      # Whether to run k-fold or standard training\n",
    "}\n",
    "\n",
    "# Device configuration\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "if torch.cuda.is_available():\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    try:\n",
    "        torch.cuda.set_per_process_memory_fraction(0.85)\n",
    "    except:\n",
    "        pass\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Enhanced data transforms with stronger augmentations\n",
    "def get_data_transforms(augmentation_strength='medium'):\n",
    "    if augmentation_strength == 'strong':\n",
    "        # Stronger augmentations for better generalization\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.2),  # X-rays might be flipped\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.RandomAffine(\n",
    "                degrees=20, translate=(0.15, 0.15), \n",
    "                scale=(0.85, 1.15), shear=10),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
    "            transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "            transforms.RandomAutocontrast(p=0.3),\n",
    "            transforms.RandomEqualize(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.2, scale=(0.02, 0.15)),\n",
    "        ])\n",
    "    elif augmentation_strength == 'medium':\n",
    "        # Medium augmentations\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.1),\n",
    "        ])\n",
    "    else:\n",
    "        # Light augmentations\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    # Validation transforms\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        'train': train_transform,\n",
    "        'val': val_transform,\n",
    "        'test': val_transform\n",
    "    }\n",
    "\n",
    "# Get data transforms\n",
    "data_transforms = get_data_transforms(CONFIG.get('augmentation_strength', 'strong'))\n",
    "\n",
    "# Create class-specific transforms for problematic classes\n",
    "def get_transform_for_class(class_idx, phase='train'):\n",
    "    if phase != 'train':\n",
    "        return data_transforms[phase]\n",
    "    \n",
    "    # Enhanced augmentation for classes with lower performance\n",
    "    if class_idx in [3, 5]:  # 's3' and 'un' classes\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "            transforms.RandomHorizontalFlip(p=0.7),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomAffine(\n",
    "                degrees=30, translate=(0.2, 0.2), \n",
    "                scale=(0.8, 1.2), shear=15),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.3, contrast=0.3, saturation=0.2, hue=0.2),\n",
    "            transforms.RandomAutocontrast(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.3, scale=(0.02, 0.2)),\n",
    "        ])\n",
    "    else:\n",
    "        # Use standard strong augmentation for other classes\n",
    "        return data_transforms['train']\n",
    "\n",
    "# Custom dataset class for class-specific augmentation\n",
    "class ClassSpecificImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        \n",
    "        # Apply class-specific transform\n",
    "        transform = get_transform_for_class(target, 'train')\n",
    "        sample = transform(sample)\n",
    "        \n",
    "        return sample, target\n",
    "\n",
    "# Mixup augmentation for training\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Applies mixup augmentation to a batch of images\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Applies mixup criterion to the predictions\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# Focal Loss implementation for handling class imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Weight for each class\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # Get CrossEntropyLoss\n",
    "        ce_loss = F.cross_entropy(\n",
    "            inputs, targets, \n",
    "            weight=self.alpha, \n",
    "            reduction='none'\n",
    "        )\n",
    "        \n",
    "        # Get probabilities\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        # Apply reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Class-Balanced Loss for better handling of imbalanced classes\n",
    "class ClassBalancedLoss(nn.Module):\n",
    "    def __init__(self, samples_per_class, num_classes=6, beta=0.9999, gamma=2.0):\n",
    "        super(ClassBalancedLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Calculate effective number of samples\n",
    "        effective_num = 1.0 - np.power(beta, samples_per_class)\n",
    "        effective_num = np.where(effective_num == 0, 1e-8, effective_num)  # Avoid division by zero\n",
    "        \n",
    "        self.weights = (1.0 - beta) / np.array(effective_num)\n",
    "        self.weights = self.weights / np.sum(self.weights) * num_classes\n",
    "        self.weights = torch.tensor(self.weights).float().to(device)\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # Get probabilities\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        # Get target probabilities\n",
    "        target_one_hot = F.one_hot(targets, self.num_classes).float()\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        pt = torch.sum(target_one_hot * probs, dim=1)\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        # Apply class balanced weights\n",
    "        cb_loss = torch.mean(self.weights[targets] * focal_loss)\n",
    "        \n",
    "        return cb_loss\n",
    "\n",
    "# Custom learning rate scheduler with warmup\n",
    "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, min_lr_ratio=0.0):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(min_lr_ratio, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# Enhanced BEiT model with attention mechanism\n",
    "class EnhancedBeitClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=6, dropout_rate=0.3, freeze_backbone=False):\n",
    "        super(EnhancedBeitClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained BEiT model with finetuned weights\n",
    "        try:\n",
    "            self.beit = BeitModel.from_pretrained(CONFIG['beit_model'])\n",
    "            print(f\"Successfully loaded BEiT model: {CONFIG['beit_model']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading BEiT model: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Get feature dimension\n",
    "        self.feature_dim = self.beit.config.hidden_size\n",
    "        print(f\"BEiT feature dimension: {self.feature_dim}\")\n",
    "        \n",
    "        # Add self-attention layer after feature extraction\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=self.feature_dim, num_heads=8, dropout=0.1)\n",
    "        \n",
    "        # Layer normalization for more stable training\n",
    "        self.norm = nn.LayerNorm(self.feature_dim)\n",
    "        \n",
    "        # Improved classifier with additional layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.feature_dim, 768),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(768),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(768, 384),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(384),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(384, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize classifier weights\n",
    "        self._init_classifier()\n",
    "        \n",
    "        # Option to freeze backbone\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        if freeze_backbone:\n",
    "            self._freeze_backbone()\n",
    "    \n",
    "    def _init_classifier(self):\n",
    "        \"\"\"Initialize classifier weights properly\"\"\"\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _freeze_backbone(self):\n",
    "        \"\"\"Freeze the BEiT backbone\"\"\"\n",
    "        for param in self.beit.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze the BEiT backbone\"\"\"\n",
    "        for param in self.beit.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.freeze_backbone = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from BEiT with or without gradient\n",
    "        if self.freeze_backbone:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.beit(x)\n",
    "        else:\n",
    "            outputs = self.beit(x)\n",
    "        \n",
    "        # Get CLS token\n",
    "        cls_token = outputs.last_hidden_state[:, 0]\n",
    "        \n",
    "        # Apply self-attention\n",
    "        cls_token_unsqueezed = cls_token.unsqueeze(0)  # Add sequence dimension\n",
    "        attn_output, _ = self.attention(\n",
    "            cls_token_unsqueezed, \n",
    "            cls_token_unsqueezed, \n",
    "            cls_token_unsqueezed\n",
    "        )\n",
    "        cls_token = attn_output.squeeze(0)  # Remove sequence dimension\n",
    "        \n",
    "        # Apply layer norm\n",
    "        normalized = self.norm(cls_token)\n",
    "        \n",
    "        # Apply classifier\n",
    "        logits = self.classifier(normalized)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Ensemble model for improved performance\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model_paths, num_classes):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList()\n",
    "        \n",
    "        # Load models\n",
    "        for path in model_paths:\n",
    "            # Create a new model\n",
    "            model = EnhancedBeitClassifier(num_classes=num_classes)\n",
    "            \n",
    "            # Load weights\n",
    "            checkpoint = torch.load(path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            # Set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # Add to model list\n",
    "            self.models.append(model)\n",
    "            \n",
    "        print(f\"Created ensemble with {len(self.models)} models\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get predictions from each model\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            with torch.no_grad():\n",
    "                outputs.append(model(x))\n",
    "        \n",
    "        # Average the logits\n",
    "        return torch.mean(torch.stack(outputs), dim=0)\n",
    "\n",
    "# K-Fold Ensemble model\n",
    "class KFoldEnsemble(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(KFoldEnsemble, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs.append(model(x))\n",
    "        \n",
    "        # Average the outputs\n",
    "        return torch.mean(torch.stack(outputs), dim=0)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load dataset with enhanced handling for 6 classes and class-specific augmentation\"\"\"\n",
    "    try:\n",
    "        # Create train dataset with class-specific transforms\n",
    "        train_dataset = ClassSpecificImageFolder(os.path.join(CONFIG['data_dir'], 'train'))\n",
    "        \n",
    "        # Create validation and test datasets with standard transforms\n",
    "        image_datasets = {'train': train_dataset}\n",
    "        for split in ['val', 'test']:\n",
    "            if os.path.exists(os.path.join(CONFIG['data_dir'], split)):\n",
    "                image_datasets[split] = datasets.ImageFolder(\n",
    "                    os.path.join(CONFIG['data_dir'], split),\n",
    "                    data_transforms[split]\n",
    "                )\n",
    "        \n",
    "        # Get class names\n",
    "        class_names = image_datasets['train'].classes\n",
    "        print(f\"Classes: {class_names}\")\n",
    "        CONFIG['num_classes'] = len(class_names)  # Update config with actual number of classes\n",
    "        \n",
    "        # Print dataset info\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            if os.path.exists(os.path.join(CONFIG['data_dir'], split)):\n",
    "                labels = [label for _, label in image_datasets[split].samples]\n",
    "                unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "                print(f\"{split} dataset:\")\n",
    "                for i, class_name in enumerate(class_names):\n",
    "                    class_idx = np.where(unique_labels == i)[0]\n",
    "                    class_count = counts[class_idx[0]] if len(class_idx) > 0 else 0\n",
    "                    print(f\"  {class_name}: {class_count} images\")\n",
    "        \n",
    "        # Calculate class weights based on training set distribution\n",
    "        if len(class_names) == CONFIG['num_classes']:\n",
    "            train_labels = np.array([label for _, label in image_datasets['train'].samples])\n",
    "            class_counts = np.bincount(train_labels, minlength=CONFIG['num_classes'])\n",
    "            \n",
    "            # Use provided class weights but print statistics\n",
    "            print(f\"Class distribution: {class_counts}\")\n",
    "            print(f\"Using class weights: {CONFIG['class_weights']}\")\n",
    "        \n",
    "        # Create weighted sampler for training to handle class imbalance\n",
    "        train_labels = np.array([label for _, label in image_datasets['train'].samples])\n",
    "        weights = np.array(CONFIG['class_weights'])[train_labels]\n",
    "        \n",
    "        sampler = torch.utils.data.WeightedRandomSampler(\n",
    "            weights=weights,\n",
    "            num_samples=len(weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        # Create data loaders with enhanced settings\n",
    "        dataloaders = {\n",
    "            'train': torch.utils.data.DataLoader(\n",
    "                image_datasets['train'],\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                sampler=sampler,\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "                drop_last=True\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Add validation and test dataloaders if available\n",
    "        for split in ['val', 'test']:\n",
    "            if os.path.exists(os.path.join(CONFIG['data_dir'], split)):\n",
    "                dataloaders[split] = torch.utils.data.DataLoader(\n",
    "                    image_datasets[split],\n",
    "                    batch_size=CONFIG['eval_batch_size'],\n",
    "                    shuffle=False,\n",
    "                    num_workers=0,\n",
    "                    pin_memory=True\n",
    "                )\n",
    "        \n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in image_datasets.keys()}\n",
    "        print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "        \n",
    "        return dataloaders, dataset_sizes, class_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# New K-Fold Data Loader\n",
    "def load_data_kfold():\n",
    "    \"\"\"Load and prepare data for k-fold cross validation\"\"\"\n",
    "    try:\n",
    "        # Load all data (train, val, test)\n",
    "        full_dataset = ClassSpecificImageFolder(os.path.join(CONFIG['data_dir'], 'train'))\n",
    "        \n",
    "        # Add val and test data to get a larger dataset for cross-validation\n",
    "        val_dataset = None\n",
    "        test_dataset = None\n",
    "        \n",
    "        if os.path.exists(os.path.join(CONFIG['data_dir'], 'val')):\n",
    "            val_dataset = datasets.ImageFolder(\n",
    "                os.path.join(CONFIG['data_dir'], 'val'),\n",
    "                data_transforms['train']  # Use train transforms for all data\n",
    "            )\n",
    "        \n",
    "        if os.path.exists(os.path.join(CONFIG['data_dir'], 'test')):\n",
    "            test_dataset = datasets.ImageFolder(\n",
    "                os.path.join(CONFIG['data_dir'], 'test'),\n",
    "                data_transforms['train']  # Use train transforms for all data\n",
    "            )\n",
    "        \n",
    "        # Combine all datasets for cross-validation\n",
    "        all_datasets = [full_dataset]\n",
    "        if val_dataset:\n",
    "            all_datasets.append(val_dataset)\n",
    "        if test_dataset:\n",
    "            all_datasets.append(test_dataset)\n",
    "        \n",
    "        # Merge all datasets for k-fold cross-validation\n",
    "        combined_dataset = ConcatDataset(all_datasets)\n",
    "        \n",
    "        # Get class names from the original dataset\n",
    "        class_names = full_dataset.classes\n",
    "        print(f\"Classes: {class_names}\")\n",
    "        CONFIG['num_classes'] = len(class_names)\n",
    "        \n",
    "        # Get all labels for stratification\n",
    "        all_labels = []\n",
    "        for dataset in all_datasets:\n",
    "            all_labels.extend([label for _, label in dataset.samples])\n",
    "        \n",
    "        # Print overall dataset statistics\n",
    "        unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "        print(f\"Combined dataset:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            class_idx = np.where(unique_labels == i)[0]\n",
    "            class_count = counts[class_idx[0]] if len(class_idx) > 0 else 0\n",
    "            print(f\"  {class_name}: {class_count} images\")\n",
    "        \n",
    "        # Count total samples\n",
    "        total_samples = len(combined_dataset)\n",
    "        print(f\"Total dataset size for k-fold: {total_samples} images\")\n",
    "        \n",
    "        return combined_dataset, class_names, all_labels\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for k-fold: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# Function to create dataloaders for a specific fold\n",
    "def create_fold_dataloaders(dataset, train_idx, val_idx, class_names):\n",
    "    \"\"\"Create train and validation dataloaders for a specific fold\"\"\"\n",
    "    \n",
    "    # Create train and validation subsets\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    \n",
    "    # Extract labels for the current fold's training set (for weighted sampling)\n",
    "    train_labels = []\n",
    "    for idx in train_idx:\n",
    "        # Handle both ImageFolder and ConcatDataset\n",
    "        if isinstance(dataset, ConcatDataset):\n",
    "            # Find which dataset the index belongs to\n",
    "            dataset_idx = 0\n",
    "            idx_tmp = idx\n",
    "            while idx_tmp >= len(dataset.datasets[dataset_idx]):\n",
    "                idx_tmp -= len(dataset.datasets[dataset_idx])\n",
    "                dataset_idx += 1\n",
    "            train_labels.append(dataset.datasets[dataset_idx].samples[idx_tmp][1])\n",
    "        else:\n",
    "            train_labels.append(dataset.samples[idx][1])\n",
    "    \n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    # Calculate class distribution for this fold\n",
    "    class_counts = np.bincount(train_labels, minlength=CONFIG['num_classes'])\n",
    "    print(f\"Fold train class distribution: {class_counts}\")\n",
    "    \n",
    "    # Create weighted sampler for the training fold\n",
    "    weights = np.array(CONFIG['class_weights'])[train_labels]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(\n",
    "        weights=weights,\n",
    "        num_samples=len(weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    # Create data loaders for this fold\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        sampler=sampler,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=CONFIG['eval_batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Create dataloader dictionary and sizes\n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader\n",
    "    }\n",
    "    \n",
    "    dataset_sizes = {\n",
    "        'train': len(train_subset),\n",
    "        'val': len(val_subset)\n",
    "    }\n",
    "    \n",
    "    return dataloaders, dataset_sizes\n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler=None, num_epochs=30):\n",
    "    \"\"\"Train the enhanced BEiT model with improved techniques for multi-class classification\"\"\"\n",
    "    since = time.time()\n",
    "    \n",
    "    # Set up checkpoint directory\n",
    "    checkpoint_dir = 'checkpoints'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Best model tracking\n",
    "    best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "    best_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_metric = 0.0  # Track the optimization metric\n",
    "    \n",
    "    # History tracking\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
    "        'val_f1_macro': [], 'val_f1_weighted': []\n",
    "    }\n",
    "    \n",
    "    # Gradient scaling for mixed precision\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CONFIG['use_mixed_precision'])\n",
    "    \n",
    "    # Early stopping\n",
    "    patience = CONFIG.get('patience', 10)\n",
    "    counter = 0\n",
    "    \n",
    "    # Gradient accumulation\n",
    "    grad_accum_steps = CONFIG['gradient_accumulation_steps']\n",
    "    \n",
    "    # Evaluation phase (val or test)\n",
    "    eval_phase = 'val' if 'val' in dataloaders else 'test'\n",
    "    \n",
    "    # Mixup settings\n",
    "    use_mixup = CONFIG.get('use_mixup', True)\n",
    "    mixup_alpha = CONFIG.get('mixup_alpha', 0.2)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 30)\n",
    "        \n",
    "        # Unfreeze backbone if specified\n",
    "        if epoch == CONFIG.get('freeze_backbone_epochs', 0) and model.freeze_backbone:\n",
    "            print(\"Unfreezing backbone for fine-tuning...\")\n",
    "            model.unfreeze_backbone()\n",
    "            # Adjust optimizer if needed\n",
    "            if hasattr(optimizer, 'param_groups'):\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    if 'beit' in param_group.get('name', ''):\n",
    "                        param_group['lr'] = CONFIG['learning_rate'] * 0.1\n",
    "        \n",
    "        # Each epoch has training and validation phases\n",
    "        for phase in ['train', eval_phase]:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "            all_probs = []\n",
    "            \n",
    "            # Reset gradient accumulation counter\n",
    "            accum_step = 0\n",
    "            \n",
    "            # Process data with progress bar\n",
    "            pbar = tqdm(dataloaders[phase], desc=phase)\n",
    "            \n",
    "            for inputs, labels in pbar:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero gradients only when accumulation steps reached\n",
    "                if phase == 'train' and accum_step % grad_accum_steps == 0:\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass with mixed precision in training\n",
    "                with torch.cuda.amp.autocast(enabled=CONFIG['use_mixed_precision']):\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        # Apply mixup in training phase if enabled\n",
    "                        if phase == 'train' and use_mixup and np.random.random() < 0.5:\n",
    "                            # Apply mixup\n",
    "                            inputs_mixed, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=mixup_alpha)\n",
    "                            outputs = model(inputs_mixed)\n",
    "                            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "                            \n",
    "                            # For predictions collection (use first target for simplicity)\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            all_labels.extend(targets_a.cpu().numpy())\n",
    "                            all_preds.extend(preds.cpu().numpy())\n",
    "                        else:\n",
    "                            # Standard forward pass\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            \n",
    "                            # Get predictions\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            \n",
    "                            # Collect predictions and labels\n",
    "                            all_labels.extend(labels.cpu().numpy())\n",
    "                            all_preds.extend(preds.cpu().numpy())\n",
    "                            \n",
    "                            # Get probabilities for metrics in validation phase\n",
    "                            if phase != 'train':\n",
    "                                probs = F.softmax(outputs, dim=1)\n",
    "                                all_probs.extend(probs.cpu().numpy())\n",
    "                        \n",
    "                        # Scale loss for gradient accumulation in training\n",
    "                        if phase == 'train':\n",
    "                            loss = loss / grad_accum_steps\n",
    "                        \n",
    "                        # Backward + optimize only in training phase\n",
    "                        if phase == 'train':\n",
    "                            # Use scaler for mixed precision\n",
    "                            scaler.scale(loss).backward()\n",
    "                            \n",
    "                            # Step optimizer if accumulation steps reached\n",
    "                            if (accum_step + 1) % grad_accum_steps == 0:\n",
    "                                # Unscale for gradient clipping\n",
    "                                scaler.unscale_(optimizer)\n",
    "                                \n",
    "                                # Clip gradients\n",
    "                                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                                \n",
    "                                # Optimizer step with scaler\n",
    "                                scaler.step(optimizer)\n",
    "                                scaler.update()\n",
    "                                \n",
    "                                # Step scheduler if provided\n",
    "                                if scheduler is not None:\n",
    "                                    if CONFIG.get('scheduler', 'cosine_warmup') == 'cosine_warmup':\n",
    "                                        scheduler.step()\n",
    "                            \n",
    "                            accum_step += 1\n",
    "                \n",
    "                # Statistics - scale loss back up for reporting\n",
    "                if phase == 'train':\n",
    "                    current_loss = loss.item() * inputs.size(0) * grad_accum_steps\n",
    "                else:\n",
    "                    current_loss = loss.item() * inputs.size(0)\n",
    "                \n",
    "                running_loss += current_loss\n",
    "                \n",
    "                # Update progress bar\n",
    "                current_loss_avg = running_loss / ((pbar.n + 1) * inputs.size(0))\n",
    "                pbar.set_postfix({'loss': f'{current_loss_avg:.4f}'})\n",
    "                \n",
    "                # Clean up memory\n",
    "                del inputs, outputs, loss\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Calculate epoch metrics\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            all_labels = np.array(all_labels)\n",
    "            all_preds = np.array(all_preds)\n",
    "            \n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            else:\n",
    "                # Calculate additional validation metrics for multi-class\n",
    "                try:\n",
    "                    all_probs = np.array(all_probs)\n",
    "                    \n",
    "                    # Calculate precision, recall, f1 for multi-class classification\n",
    "                    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "                    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "                    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "                    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "                    \n",
    "                    # Calculate confusion matrix\n",
    "                    cm = confusion_matrix(all_labels, all_preds)\n",
    "                    \n",
    "                    # Store validation metrics\n",
    "                    history['val_loss'].append(epoch_loss)\n",
    "                    history['val_acc'].append(epoch_acc)\n",
    "                    history['val_precision'].append(precision)\n",
    "                    history['val_recall'].append(recall)\n",
    "                    history['val_f1'].append(f1)\n",
    "                    history['val_f1_macro'].append(f1_macro)\n",
    "                    \n",
    "                    # Print detailed metrics\n",
    "                    print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                    print(f'Precision: {precision:.4f} Recall: {recall:.4f}')\n",
    "                    print(f'F1 (weighted): {f1:.4f} F1 (macro): {f1_macro:.4f}')\n",
    "                    \n",
    "                    # Choose optimization metric based on configuration\n",
    "                    optimization_metric = CONFIG.get('optimization_metric', 'f1_macro')\n",
    "                    if optimization_metric == 'f1_macro':\n",
    "                        current_metric = f1_macro\n",
    "                    elif optimization_metric == 'f1_weighted':\n",
    "                        current_metric = f1\n",
    "                    elif optimization_metric == 'accuracy':\n",
    "                        current_metric = epoch_acc\n",
    "                    else:\n",
    "                        current_metric = f1_macro\n",
    "                    \n",
    "                    # Check if this is the best model\n",
    "                    improved = False\n",
    "                    if current_metric > best_metric:\n",
    "                        best_metric = current_metric\n",
    "                        improved = True\n",
    "                        metric_name = optimization_metric\n",
    "                    \n",
    "                    # Save best metrics independently as well\n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                    if f1 > best_f1:\n",
    "                        best_f1 = f1\n",
    "                    \n",
    "                    if improved:\n",
    "                        counter = 0\n",
    "                        print(f\"Saving best model (improved {metric_name}: {current_metric:.4f})\")\n",
    "                        \n",
    "                        # Save model checkpoint\n",
    "                        torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'metrics': {\n",
    "                                'accuracy': epoch_acc,\n",
    "                                'precision': precision,\n",
    "                                'recall': recall,\n",
    "                                'f1_weighted': f1,\n",
    "                                'f1_macro': f1_macro,\n",
    "                                'confusion_matrix': cm.tolist()\n",
    "                            },\n",
    "                            'history': history\n",
    "                        }, best_model_path)\n",
    "                        \n",
    "                        # Also save epoch-specific checkpoint for potential ensemble\n",
    "                        torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'metrics': {\n",
    "                                'accuracy': epoch_acc,\n",
    "                                'f1_weighted': f1,\n",
    "                                'f1_macro': f1_macro\n",
    "                            }\n",
    "                        }, os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt'))\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f\"Early stopping counter: {counter}/{patience}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    import traceback\n",
    "                    print(f\"Error calculating metrics: {e}\")\n",
    "                    traceback.print_exc()\n",
    "            \n",
    "            # Clean memory after each phase\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Calculate training time\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best metrics: Acc: {best_acc:.4f}, F1 (weighted): {best_f1:.4f}, Best {CONFIG[\"optimization_metric\"]}: {best_metric:.4f}')\n",
    "    \n",
    "    # Load best model weights\n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_metrics = checkpoint.get('metrics', {})\n",
    "        print(\"Loaded best model from checkpoint\")\n",
    "        \n",
    "        # Print best model metrics\n",
    "        if best_metrics:\n",
    "            print(\"\\nBest model metrics:\")\n",
    "            for k, v in best_metrics.items():\n",
    "                if k != 'confusion_matrix':\n",
    "                    print(f\"  {k}: {v:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def plot_training_results(history):\n",
    "    \"\"\"Plot enhanced training curves with more metrics for multi-class\"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot precision, recall, f1\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(history['val_precision'], label='Precision (weighted)')\n",
    "    plt.plot(history['val_recall'], label='Recall (weighted)')\n",
    "    plt.plot(history['val_f1'], label='F1 Score (weighted)')\n",
    "    plt.title('Precision, Recall, and F1 Score (Weighted)')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot F1 scores (macro vs weighted)\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(history['val_f1'], label='F1 (weighted)')\n",
    "    plt.plot(history['val_f1_macro'], label='F1 (macro)')\n",
    "    plt.title('F1 Scores (Macro vs Weighted)')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Extract metrics with matching epochs\n",
    "    epochs = range(1, len(history['val_precision']) + 1)\n",
    "    \n",
    "    # Plot precision vs recall\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.scatter(history['val_recall'], history['val_precision'], c=epochs, cmap='viridis')\n",
    "    plt.colorbar(label='Epoch')\n",
    "    \n",
    "    # Add annotations for some points\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        if i % 5 == 0 or i == len(epochs) - 1:  # Annotate every 5th epoch and last epoch\n",
    "            plt.annotate(\n",
    "                f'{epoch}', \n",
    "                (history['val_recall'][i], history['val_precision'][i]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 10),\n",
    "                ha='center'\n",
    "            )\n",
    "    \n",
    "    plt.title('Precision vs Recall (Weighted)')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot F1 macro vs Accuracy\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.scatter(history['val_acc'], history['val_f1_macro'], c=epochs, cmap='viridis')\n",
    "    plt.colorbar(label='Epoch')\n",
    "    \n",
    "    # Add annotations for some points\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        if i % 5 == 0 or i == len(epochs) - 1:  # Annotate every 5th epoch and last epoch\n",
    "            plt.annotate(\n",
    "                f'{epoch}', \n",
    "                (history['val_acc'][i], history['val_f1_macro'][i]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 10),\n",
    "                ha='center'\n",
    "            )\n",
    "    \n",
    "    plt.title('F1 Macro vs Accuracy')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('F1 Macro')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhanced_beit_multiclass_training_results.png', dpi=300)\n",
    "\n",
    "def evaluate_model(model, dataloader, class_names):\n",
    "    \"\"\"Enhanced evaluation for multi-class classification\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Collect predictions\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Use mixed precision for inference\n",
    "            with torch.cuda.amp.autocast(enabled=CONFIG['use_mixed_precision']):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Collect results\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Clean memory\n",
    "            del inputs, outputs, preds, probs\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    # Convert to arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate standard metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # Calculate precision, recall, f1 for multi-class classification\n",
    "    precision_weighted = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    precision_per_class = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\n===== MULTI-CLASS MODEL EVALUATION =====\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted Metrics:\")\n",
    "    print(f\"  Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"  Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_weighted:.4f}\")\n",
    "    print(f\"Macro Metrics:\")\n",
    "    print(f\"  Precision: {precision_macro:.4f}\")\n",
    "    print(f\"  Recall: {recall_macro:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if i < len(precision_per_class):\n",
    "            print(f\"  {class_name}:\")\n",
    "            print(f\"    Precision: {precision_per_class[i]:.4f}\")\n",
    "            print(f\"    Recall: {recall_per_class[i]:.4f}\")\n",
    "            print(f\"    F1 Score: {f1_per_class[i]:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix with improved visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create a normalized confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    im = plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues, vmin=0, vmax=1)\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    # Add class labels\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm_normalized.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, f\"{cm[i, j]}\\n({cm_normalized[i, j]:.2f})\",\n",
    "                   horizontalalignment=\"center\", fontsize=9,\n",
    "                   color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('enhanced_beit_multiclass_cm.png', dpi=300)\n",
    "    \n",
    "    # Plot per-class metrics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    # Plot bars for precision, recall, and F1 for each class\n",
    "    plt.bar(x - width, precision_per_class, width, label='Precision')\n",
    "    plt.bar(x, recall_per_class, width, label='Recall')\n",
    "    plt.bar(x + width, f1_per_class, width, label='F1 Score')\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Per-Class Performance Metrics')\n",
    "    plt.xticks(x, class_names, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhanced_beit_multiclass_per_class_metrics.png', dpi=300)\n",
    "    \n",
    "    # Return comprehensive metrics\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_per_class': precision_per_class.tolist(),\n",
    "        'recall_per_class': recall_per_class.tolist(),\n",
    "        'f1_per_class': f1_per_class.tolist(),\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'class_names': class_names\n",
    "    }\n",
    "\n",
    "def create_ensemble():\n",
    "    \"\"\"Create ensemble from saved model checkpoints\"\"\"\n",
    "    # Get the paths of saved checkpoints\n",
    "    checkpoint_dir = 'checkpoints'\n",
    "    \n",
    "    # Use the configured ensemble epochs or default epochs\n",
    "    ensemble_epochs = CONFIG.get('ensemble_epochs', [25, 35, 45, 55])\n",
    "    \n",
    "    model_paths = [\n",
    "        os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "        for epoch in ensemble_epochs\n",
    "        if os.path.exists(os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt'))\n",
    "    ]\n",
    "    \n",
    "    if len(model_paths) > 1:\n",
    "        print(f\"Creating ensemble from {len(model_paths)} checkpoints: {ensemble_epochs}\")\n",
    "        ensemble = EnsembleModel(model_paths, CONFIG['num_classes'])\n",
    "        ensemble = ensemble.to(device)\n",
    "        \n",
    "        # Save the ensemble\n",
    "        torch.save({\n",
    "            'model_type': 'ensemble',\n",
    "            'model_paths': model_paths,\n",
    "            'config': CONFIG\n",
    "        }, 'ensemble_model.pth')\n",
    "        \n",
    "        return ensemble\n",
    "    else:\n",
    "        print(\"Not enough models for ensemble\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"=== Enhanced BEiT Multi-Class Classification ===\")\n",
    "        \n",
    "        # Load dataset with enhanced augmentations\n",
    "        print(\"Loading multi-class dataset with enhanced augmentations...\")\n",
    "        dataloaders, dataset_sizes, class_names = load_data()\n",
    "        \n",
    "        # Create enhanced BEiT model\n",
    "        print(\"Creating enhanced BEiT model with attention...\")\n",
    "        model = EnhancedBeitClassifier(\n",
    "            num_classes=CONFIG['num_classes'],\n",
    "            dropout_rate=CONFIG.get('dropout_rate', 0.3),\n",
    "            freeze_backbone=CONFIG.get('freeze_backbone_epochs', 0) > 0\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Get class counts for class-balanced loss\n",
    "        train_labels = np.array([label for _, label in dataloaders['train'].dataset.samples])\n",
    "        class_counts = np.bincount(train_labels, minlength=CONFIG['num_classes'])\n",
    "        \n",
    "        # Create loss function\n",
    "        if CONFIG.get('use_class_balanced_loss', True):\n",
    "            # Create class-balanced loss\n",
    "            criterion = ClassBalancedLoss(\n",
    "                samples_per_class=class_counts,\n",
    "                num_classes=CONFIG['num_classes'],\n",
    "                beta=0.9999,\n",
    "                gamma=CONFIG.get('focal_loss_gamma', 3.0)\n",
    "            )\n",
    "            print(f\"Using Class-Balanced Loss with gamma={CONFIG.get('focal_loss_gamma', 3.0)}\")\n",
    "        else:\n",
    "            # Create standard focal loss with class weights\n",
    "            weights = torch.tensor(CONFIG['class_weights']).float().to(device)\n",
    "            \n",
    "            criterion = FocalLoss(\n",
    "                gamma=CONFIG.get('focal_loss_gamma', 3.0),\n",
    "                alpha=weights\n",
    "            )\n",
    "            print(f\"Using Focal Loss (gamma={CONFIG.get('focal_loss_gamma', 3.0)}) with class weights\")\n",
    "        \n",
    "        # Create optimizer with weight decay\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=CONFIG['learning_rate'],\n",
    "            weight_decay=CONFIG.get('weight_decay', 0.04),\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # Create scheduler\n",
    "        if CONFIG.get('scheduler', 'cosine_warmup') == 'cosine_warmup':\n",
    "            # Calculate total steps and warmup steps\n",
    "            total_steps = CONFIG['num_epochs'] * len(dataloaders['train'])\n",
    "            warmup_steps = CONFIG['warmup_epochs'] * len(dataloaders['train'])\n",
    "            \n",
    "            # Create custom scheduler with warmup\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, \n",
    "                warmup_steps, \n",
    "                total_steps, \n",
    "                min_lr_ratio=0.01\n",
    "            )\n",
    "            print(f\"Using custom cosine scheduler with {CONFIG['warmup_epochs']} epochs of warmup\")\n",
    "        elif CONFIG.get('scheduler', '') == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=CONFIG['num_epochs'],\n",
    "                eta_min=CONFIG['learning_rate'] * 0.001\n",
    "            )\n",
    "            print(\"Using Cosine Annealing scheduler\")\n",
    "        else:\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='max',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                verbose=True\n",
    "            )\n",
    "            print(\"Using ReduceLROnPlateau scheduler\")\n",
    "        \n",
    "        # Check if we should try to load a previous checkpoint\n",
    "        if CONFIG.get('use_checkpoint', False):\n",
    "            checkpoint_path = 'checkpoints/best_model.pt'\n",
    "            if os.path.exists(checkpoint_path):\n",
    "                checkpoint = torch.load(checkpoint_path)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "                print(f\"Loaded checkpoint from epoch {start_epoch-1}\")\n",
    "                \n",
    "                # Print metrics from checkpoint\n",
    "                if 'metrics' in checkpoint:\n",
    "                    print(\"Checkpoint metrics:\")\n",
    "                    for k, v in checkpoint['metrics'].items():\n",
    "                        if k != 'confusion_matrix':\n",
    "                            print(f\"  {k}: {v:.4f}\")\n",
    "                \n",
    "                # Ask for confirmation before continuing training\n",
    "                confirmation = input(\"Continue training from checkpoint? (y/n): \")\n",
    "                if confirmation.lower() != 'y':\n",
    "                    print(\"Starting fresh training...\")\n",
    "                    # Create fresh model\n",
    "                    model = EnhancedBeitClassifier(\n",
    "                        num_classes=CONFIG['num_classes'],\n",
    "                        dropout_rate=CONFIG.get('dropout_rate', 0.3),\n",
    "                        freeze_backbone=CONFIG.get('freeze_backbone_epochs', 0) > 0\n",
    "                    )\n",
    "                    model = model.to(device)\n",
    "                    \n",
    "                    # Create fresh optimizer\n",
    "                    optimizer = optim.AdamW(\n",
    "                        model.parameters(),\n",
    "                        lr=CONFIG['learning_rate'],\n",
    "                        weight_decay=CONFIG.get('weight_decay', 0.04),\n",
    "                        eps=1e-8\n",
    "                    )\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Starting model training with enhanced techniques...\")\n",
    "        model, history = train_model(\n",
    "            model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, \n",
    "            num_epochs=CONFIG['num_epochs']\n",
    "        )\n",
    "        \n",
    "        # Plot results\n",
    "        plot_training_results(history)\n",
    "        \n",
    "        # Comprehensive evaluation\n",
    "        print(\"Performing comprehensive evaluation...\")\n",
    "        test_phase = 'test' if 'test' in dataloaders else 'val'\n",
    "        metrics = evaluate_model(model, dataloaders[test_phase], class_names)\n",
    "        \n",
    "        # Try to create ensemble if enabled\n",
    "        if CONFIG.get('use_ensemble', True):\n",
    "            print(\"Creating and evaluating ensemble model...\")\n",
    "            ensemble = create_ensemble()\n",
    "            if ensemble is not None:\n",
    "                ensemble_metrics = evaluate_model(ensemble, dataloaders[test_phase], class_names)\n",
    "                print(\"\\nEnsemble vs Single Model Comparison:\")\n",
    "                print(f\"Single Model F1 Macro: {metrics['f1_macro']:.4f}\")\n",
    "                print(f\"Ensemble Model F1 Macro: {ensemble_metrics['f1_macro']:.4f}\")\n",
    "                \n",
    "                # Use ensemble for final model if it's better\n",
    "                if ensemble_metrics['f1_macro'] > metrics['f1_macro']:\n",
    "                    print(\"Ensemble model performs better - using it as final model\")\n",
    "                    model = ensemble\n",
    "                    metrics = ensemble_metrics\n",
    "        \n",
    "        # Save model\n",
    "        print(\"Saving enhanced model...\")\n",
    "        model = model.to('cpu')  # Move to CPU for saving\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'class_names': class_names,\n",
    "            'config': CONFIG,\n",
    "            'metrics': metrics,\n",
    "            'history': history\n",
    "        }, 'enhanced_beit_multiclass_model.pth')\n",
    "        \n",
    "        print(\"Enhanced model saved to 'enhanced_beit_multiclass_model.pth'\")\n",
    "        \n",
    "        # Create example usage code\n",
    "        usage_code = \"\"\"\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from transformers import BeitModel\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "def load_enhanced_model(model_path):\n",
    "    # Define the model class\n",
    "    class EnhancedBeitClassifier(nn.Module):\n",
    "        def __init__(self, num_classes=6, dropout_rate=0.3):\n",
    "            super(EnhancedBeitClassifier, self).__init__()\n",
    "            # Load pre-trained BEiT model\n",
    "            self.beit = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k-ft22k\")\n",
    "            self.feature_dim = self.beit.config.hidden_size\n",
    "            \n",
    "            # Add attention mechanism\n",
    "            self.attention = nn.MultiheadAttention(embed_dim=self.feature_dim, num_heads=8, dropout=0.1)\n",
    "            \n",
    "            # Layer norm\n",
    "            self.norm = nn.LayerNorm(self.feature_dim)\n",
    "            \n",
    "            # Classifier\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(self.feature_dim, 768),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(768),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(768, 384),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(384),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(384, num_classes)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Extract features\n",
    "            outputs = self.beit(x)\n",
    "            cls_token = outputs.last_hidden_state[:, 0]\n",
    "            \n",
    "            # Apply attention\n",
    "            cls_token_unsqueezed = cls_token.unsqueeze(0)\n",
    "            attn_output, _ = self.attention(cls_token_unsqueezed, cls_token_unsqueezed, cls_token_unsqueezed)\n",
    "            cls_token = attn_output.squeeze(0)\n",
    "            \n",
    "            # Apply layer norm\n",
    "            normalized = self.norm(cls_token)\n",
    "            \n",
    "            # Apply classifier\n",
    "            logits = self.classifier(normalized)\n",
    "            return logits\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    \n",
    "    # Create model and load weights\n",
    "    model = EnhancedBeitClassifier(num_classes=len(checkpoint.get('class_names', 6)))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "# Function to predict on a single image\n",
    "def predict_multiclass(model, image_path, checkpoint):\n",
    "    # Set up transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "        \n",
    "        # Get predicted class\n",
    "        _, predicted_class = torch.max(probabilities, 0)\n",
    "        predicted_class = predicted_class.item()\n",
    "    \n",
    "    # Get class name and probability\n",
    "    class_names = checkpoint.get('class_names', ['he', 's1', 's2', 's3', 's4', 'un'])\n",
    "    class_name = class_names[predicted_class]\n",
    "    probability = probabilities[predicted_class].item() * 100  # Convert to percentage\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Show the image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Prediction: {class_name} ({probability:.1f}%)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show probability bars for all classes\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_probs = probabilities.cpu().numpy() * 100\n",
    "    \n",
    "    # Sort by probability\n",
    "    sorted_idx = np.argsort(class_probs)[::-1]\n",
    "    sorted_classes = [class_names[i] for i in sorted_idx]\n",
    "    sorted_probs = class_probs[sorted_idx]\n",
    "    \n",
    "    # Plot horizontal bars\n",
    "    y_pos = np.arange(len(sorted_classes))\n",
    "    plt.barh(y_pos, sorted_probs, align='center')\n",
    "    plt.yticks(y_pos, sorted_classes)\n",
    "    plt.xlabel('Probability (%)')\n",
    "    plt.title('Class Probabilities')\n",
    "    \n",
    "    # Add probability values\n",
    "    for i, v in enumerate(sorted_probs):\n",
    "        plt.text(v + 1, i, f\"{v:.1f}%\", va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return detailed results\n",
    "    class_probabilities = {class_names[i]: probabilities[i].item() * 100 for i in range(len(class_names))}\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': class_name,\n",
    "        'confidence': probability,\n",
    "        'all_probabilities': class_probabilities\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "model, checkpoint = load_enhanced_model('enhanced_beit_multiclass_model.pth')\n",
    "result = predict_multiclass(model, 'path/to/your/image.jpg', checkpoint)\n",
    "print(f\"Prediction: {result['predicted_class']} with {result['confidence']:.1f}% confidence\")\n",
    "print(\"\\nAll class probabilities:\")\n",
    "sorted_probs = dict(sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True))\n",
    "for cls, prob in sorted_probs.items():\n",
    "    print(f\"  {cls}: {prob:.2f}%\")\n",
    "        \"\"\"\n",
    "        \n",
    "        with open('use_enhanced_multiclass_model.py', 'w') as f:\n",
    "            f.write(usage_code)\n",
    "        \n",
    "        print(\"Usage code saved to use_enhanced_multiclass_model.py\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error in main: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# K-Fold Cross-Validation implementation\n",
    "def main_kfold():\n",
    "    try:\n",
    "        print(\"=== Enhanced BEiT Multi-Class Classification with K-Fold Cross-Validation ===\")\n",
    "        \n",
    "        # Load all data for k-fold cross validation\n",
    "        print(\"Loading and preparing dataset for k-fold cross validation...\")\n",
    "        combined_dataset, class_names, all_labels = load_data_kfold()\n",
    "        \n",
    "        # Initialize k-fold cross validation\n",
    "        k_folds = CONFIG.get('k_folds', 5)\n",
    "        \n",
    "        # Choose between standard or stratified k-fold\n",
    "        if CONFIG.get('stratified', True):\n",
    "            print(f\"Using Stratified {k_folds}-Fold Cross Validation\")\n",
    "            kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "            splits = kfold.split(np.arange(len(combined_dataset)), all_labels)\n",
    "        else:\n",
    "            print(f\"Using standard {k_folds}-Fold Cross Validation\")\n",
    "            kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "            splits = kfold.split(np.arange(len(combined_dataset)))\n",
    "        \n",
    "        # Store results for each fold\n",
    "        fold_results = []\n",
    "        best_models = []\n",
    "        best_fold_score = 0\n",
    "        best_fold_idx = -1\n",
    "        \n",
    "        # Run k-fold cross validation\n",
    "        for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "            print(f\"\\n{'='*40}\")\n",
    "            print(f\"FOLD {fold+1}/{k_folds}\")\n",
    "            print(f\"{'='*40}\")\n",
    "            \n",
    "            # Create dataloaders for this fold\n",
    "            dataloaders, dataset_sizes = create_fold_dataloaders(\n",
    "                combined_dataset, train_idx, val_idx, class_names\n",
    "            )\n",
    "            \n",
    "            # Create model for this fold\n",
    "            print(f\"Creating model for fold {fold+1}...\")\n",
    "            model = EnhancedBeitClassifier(\n",
    "                num_classes=CONFIG['num_classes'],\n",
    "                dropout_rate=CONFIG.get('dropout_rate', 0.3),\n",
    "                freeze_backbone=CONFIG.get('freeze_backbone_epochs', 0) > 0\n",
    "            )\n",
    "            model = model.to(device)\n",
    "            \n",
    "            # Get class counts for class-balanced loss\n",
    "            train_labels = []\n",
    "            for idx in train_idx:\n",
    "                if isinstance(combined_dataset, ConcatDataset):\n",
    "                    # Find which dataset the index belongs to\n",
    "                    dataset_idx = 0\n",
    "                    temp_idx = idx\n",
    "                    while temp_idx >= len(combined_dataset.datasets[dataset_idx]):\n",
    "                        temp_idx -= len(combined_dataset.datasets[dataset_idx])\n",
    "                        dataset_idx += 1\n",
    "                    train_labels.append(combined_dataset.datasets[dataset_idx].samples[temp_idx][1])\n",
    "                else:\n",
    "                    train_labels.append(combined_dataset.samples[idx][1])\n",
    "            \n",
    "            train_labels = np.array(train_labels)\n",
    "            class_counts = np.bincount(train_labels, minlength=CONFIG['num_classes'])\n",
    "            \n",
    "            # Create loss function\n",
    "            if CONFIG.get('use_class_balanced_loss', True):\n",
    "                # Create class-balanced loss\n",
    "                criterion = ClassBalancedLoss(\n",
    "                    samples_per_class=class_counts,\n",
    "                    num_classes=CONFIG['num_classes'],\n",
    "                    beta=0.9999,\n",
    "                    gamma=CONFIG.get('focal_loss_gamma', 3.0)\n",
    "                )\n",
    "                print(f\"Using Class-Balanced Loss with gamma={CONFIG.get('focal_loss_gamma', 3.0)}\")\n",
    "            else:\n",
    "                # Create standard focal loss with class weights\n",
    "                weights = torch.tensor(CONFIG['class_weights']).float().to(device)\n",
    "                \n",
    "                criterion = FocalLoss(\n",
    "                    gamma=CONFIG.get('focal_loss_gamma', 3.0),\n",
    "                    alpha=weights\n",
    "                )\n",
    "                print(f\"Using Focal Loss (gamma={CONFIG.get('focal_loss_gamma', 3.0)}) with class weights\")\n",
    "            \n",
    "            # Create optimizer with weight decay\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=CONFIG['learning_rate'],\n",
    "                weight_decay=CONFIG.get('weight_decay', 0.04),\n",
    "                eps=1e-8\n",
    "            )\n",
    "            \n",
    "            # Create scheduler\n",
    "            if CONFIG.get('scheduler', 'cosine_warmup') == 'cosine_warmup':\n",
    "                # Calculate total steps and warmup steps\n",
    "                total_steps = CONFIG['num_epochs'] * len(dataloaders['train'])\n",
    "                warmup_steps = CONFIG['warmup_epochs'] * len(dataloaders['train'])\n",
    "                \n",
    "                # Create custom scheduler with warmup\n",
    "                scheduler = get_cosine_schedule_with_warmup(\n",
    "                    optimizer, \n",
    "                    warmup_steps, \n",
    "                    total_steps, \n",
    "                    min_lr_ratio=0.01\n",
    "                )\n",
    "                print(f\"Using custom cosine scheduler with {CONFIG['warmup_epochs']} epochs of warmup\")\n",
    "            else:\n",
    "                scheduler = None\n",
    "            \n",
    "            # Train model for this fold\n",
    "            print(f\"Training model for fold {fold+1}...\")\n",
    "            model, history = train_model(\n",
    "                model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, \n",
    "                num_epochs=CONFIG['num_epochs']\n",
    "            )\n",
    "            \n",
    "            # Evaluate model on validation set\n",
    "            print(f\"Evaluating model for fold {fold+1}...\")\n",
    "            metrics = evaluate_model(model, dataloaders['val'], class_names)\n",
    "            \n",
    "            # Store results for this fold\n",
    "            fold_metrics = {\n",
    "                'fold': fold + 1,\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'precision_weighted': metrics['precision_weighted'],\n",
    "                'recall_weighted': metrics['recall_weighted'],\n",
    "                'f1_weighted': metrics['f1_weighted'],\n",
    "                'f1_macro': metrics['f1_macro'],\n",
    "                'history': history\n",
    "            }\n",
    "            \n",
    "            fold_results.append(fold_metrics)\n",
    "            \n",
    "            # Store the best model across all folds\n",
    "            optimization_metric = CONFIG.get('optimization_metric', 'f1_macro')\n",
    "            current_metric = fold_metrics[optimization_metric]\n",
    "            \n",
    "            # Check if this is the best fold\n",
    "            if current_metric > best_fold_score:\n",
    "                best_fold_score = current_metric\n",
    "                best_fold_idx = fold\n",
    "                \n",
    "                # Save the best model overall\n",
    "                print(f\"New best fold! Saving model from fold {fold+1}\")\n",
    "                torch.save({\n",
    "                    'fold': fold + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'metrics': metrics,\n",
    "                    'history': history,\n",
    "                    'class_names': class_names\n",
    "                }, f'best_kfold_model.pth')\n",
    "            \n",
    "            # Save this fold's model if requested\n",
    "            if CONFIG.get('save_all_folds', True):\n",
    "                # Create folder for fold models if it doesn't exist\n",
    "                os.makedirs('fold_models', exist_ok=True)\n",
    "                \n",
    "                # Save fold model\n",
    "                torch.save({\n",
    "                    'fold': fold + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'metrics': metrics,\n",
    "                    'history': history,\n",
    "                    'class_names': class_names\n",
    "                }, f'fold_models/fold_{fold+1}_model.pth')\n",
    "            \n",
    "            # Keep model in memory for potential ensemble\n",
    "            model = model.to('cpu')  # Move to CPU to save GPU memory\n",
    "            best_models.append(model)\n",
    "            \n",
    "            # Plot training curves for this fold\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot accuracy\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "            plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "            plt.title(f'Fold {fold+1} - Model Accuracy')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.grid(alpha=0.3)\n",
    "            \n",
    "            # Plot loss\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(history['train_loss'], label='Train Loss')\n",
    "            plt.plot(history['val_loss'], label='Validation Loss')\n",
    "            plt.title(f'Fold {fold+1} - Model Loss')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.grid(alpha=0.3)\n",
    "            \n",
    "            # Plot precision, recall, f1\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(history['val_precision'], label='Precision (weighted)')\n",
    "            plt.plot(history['val_recall'], label='Recall (weighted)')\n",
    "            plt.plot(history['val_f1'], label='F1 Score (weighted)')\n",
    "            plt.title(f'Fold {fold+1} - Precision, Recall, and F1 Score')\n",
    "            plt.ylabel('Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.grid(alpha=0.3)\n",
    "            \n",
    "            # Plot F1 scores (macro vs weighted)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.plot(history['val_f1'], label='F1 (weighted)')\n",
    "            plt.plot(history['val_f1_macro'], label='F1 (macro)')\n",
    "            plt.title(f'Fold {fold+1} - F1 Scores')\n",
    "            plt.ylabel('Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.grid(alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'fold_{fold+1}_training_curves.png', dpi=200)\n",
    "            plt.close()\n",
    "            \n",
    "            # Clear some memory\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        # Create a summary DataFrame of fold results\n",
    "        results_df = pd.DataFrame(fold_results)\n",
    "        print(\"\\n=== K-Fold Cross-Validation Results ===\")\n",
    "        print(results_df[['fold', 'accuracy', 'f1_weighted', 'f1_macro']])\n",
    "        \n",
    "        # Calculate mean and std of metrics across folds\n",
    "        mean_accuracy = results_df['accuracy'].mean()\n",
    "        std_accuracy = results_df['accuracy'].std()\n",
    "        mean_f1_weighted = results_df['f1_weighted'].mean()\n",
    "        std_f1_weighted = results_df['f1_weighted'].std()\n",
    "        mean_f1_macro = results_df['f1_macro'].mean()\n",
    "        std_f1_macro = results_df['f1_macro'].std()\n",
    "        \n",
    "        print(\"\\n=== Overall Cross-Validation Performance ===\")\n",
    "        print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "        print(f\"F1 (weighted): {mean_f1_weighted:.4f} ± {std_f1_weighted:.4f}\")\n",
    "        print(f\"F1 (macro): {mean_f1_macro:.4f} ± {std_f1_macro:.4f}\")\n",
    "        \n",
    "        # Save the validation results\n",
    "        results_df.to_csv('kfold_validation_results.csv', index=False)\n",
    "        \n",
    "        # Create an ensemble from all folds if requested\n",
    "        if CONFIG.get('use_ensemble', True) and len(best_models) > 1:\n",
    "            print(\"\\n=== Creating Ensemble from All Folds ===\")\n",
    "            \n",
    "            # Create a simple ensemble model\n",
    "            ensemble_model = KFoldEnsemble(best_models).to(device)\n",
    "            \n",
    "            # Save the ensemble model info\n",
    "            torch.save({\n",
    "                'model_type': 'kfold_ensemble',\n",
    "                'num_folds': k_folds,\n",
    "                'class_names': class_names,\n",
    "            }, 'kfold_ensemble_info.pth')\n",
    "            \n",
    "            # Save individual fold models for the ensemble\n",
    "            os.makedirs('ensemble_models', exist_ok=True)\n",
    "            for i, model in enumerate(best_models):\n",
    "                torch.save({\n",
    "                    'fold': i + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                }, f'ensemble_models/fold_{i+1}_model.pth')\n",
    "            \n",
    "            print(f\"Ensemble model created from {len(best_models)} folds\")\n",
    "            print(\"Ensemble model information saved to 'kfold_ensemble_info.pth'\")\n",
    "            print(\"Individual fold models saved in 'ensemble_models/' directory\")\n",
    "            \n",
    "            # Create usage code for the ensemble model\n",
    "            usage_code = \"\"\"\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from transformers import BeitModel\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the k-fold ensemble model\n",
    "def load_kfold_ensemble(ensemble_info_path='kfold_ensemble_info.pth', models_dir='ensemble_models'):\n",
    "    # Define the model class\n",
    "    class EnhancedBeitClassifier(nn.Module):\n",
    "        def __init__(self, num_classes=6, dropout_rate=0.3):\n",
    "            super(EnhancedBeitClassifier, self).__init__()\n",
    "            # Load pre-trained BEiT model\n",
    "            self.beit = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k-ft22k\")\n",
    "            self.feature_dim = self.beit.config.hidden_size\n",
    "            \n",
    "            # Add attention mechanism\n",
    "            self.attention = nn.MultiheadAttention(embed_dim=self.feature_dim, num_heads=8, dropout=0.1)\n",
    "            \n",
    "            # Layer norm\n",
    "            self.norm = nn.LayerNorm(self.feature_dim)\n",
    "            \n",
    "            # Classifier\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(self.feature_dim, 768),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(768),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(768, 384),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(384),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(384, num_classes)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Extract features\n",
    "            outputs = self.beit(x)\n",
    "            cls_token = outputs.last_hidden_state[:, 0]\n",
    "            \n",
    "            # Apply attention\n",
    "            cls_token_unsqueezed = cls_token.unsqueeze(0)\n",
    "            attn_output, _ = self.attention(cls_token_unsqueezed, cls_token_unsqueezed, cls_token_unsqueezed)\n",
    "            cls_token = attn_output.squeeze(0)\n",
    "            \n",
    "            # Apply layer norm\n",
    "            normalized = self.norm(cls_token)\n",
    "            \n",
    "            # Apply classifier\n",
    "            logits = self.classifier(normalized)\n",
    "            return logits\n",
    "    \n",
    "    # Define the ensemble model\n",
    "    class KFoldEnsemble(nn.Module):\n",
    "        def __init__(self, models):\n",
    "            super(KFoldEnsemble, self).__init__()\n",
    "            self.models = nn.ModuleList(models)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            outputs = []\n",
    "            for model in self.models:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs.append(model(x))\n",
    "            \n",
    "            # Average the outputs\n",
    "            return torch.mean(torch.stack(outputs), dim=0)\n",
    "    \n",
    "    # Load the ensemble info\n",
    "    ensemble_info = torch.load(ensemble_info_path, map_location='cpu')\n",
    "    class_names = ensemble_info.get('class_names')\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # Create individual models\n",
    "    models = []\n",
    "    fold_paths = [f for f in os.listdir(models_dir) if f.startswith('fold_') and f.endswith('_model.pth')]\n",
    "    \n",
    "    for model_file in sorted(fold_paths):\n",
    "        # Create model\n",
    "        model = EnhancedBeitClassifier(num_classes=num_classes)\n",
    "        \n",
    "        # Load weights\n",
    "        checkpoint = torch.load(os.path.join(models_dir, model_file), map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        \n",
    "        # Add to ensemble\n",
    "        models.append(model)\n",
    "    \n",
    "    # Create the ensemble\n",
    "    ensemble = KFoldEnsemble(models)\n",
    "    ensemble.eval()\n",
    "    \n",
    "    return ensemble, ensemble_info\n",
    "\n",
    "# Function to predict with the ensemble\n",
    "def predict_with_ensemble(ensemble, image_path, ensemble_info):\n",
    "    # Set up transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = ensemble(input_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "        \n",
    "        # Get predicted class\n",
    "        _, predicted_class = torch.max(probabilities, 0)\n",
    "        predicted_class = predicted_class.item()\n",
    "    \n",
    "    # Get class name and probability\n",
    "    class_names = ensemble_info.get('class_names', ['he', 's1', 's2', 's3', 's4', 'un'])\n",
    "    class_name = class_names[predicted_class]\n",
    "    probability = probabilities[predicted_class].item() * 100  # Convert to percentage\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Show the image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Ensemble Prediction: {class_name} ({probability:.1f}%)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show probability bars for all classes\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_probs = probabilities.cpu().numpy() * 100\n",
    "    \n",
    "    # Sort by probability\n",
    "    sorted_idx = np.argsort(class_probs)[::-1]\n",
    "    sorted_classes = [class_names[i] for i in sorted_idx]\n",
    "    sorted_probs = class_probs[sorted_idx]\n",
    "    \n",
    "    # Plot horizontal bars\n",
    "    y_pos = np.arange(len(sorted_classes))\n",
    "    plt.barh(y_pos, sorted_probs, align='center')\n",
    "    plt.yticks(y_pos, sorted_classes)\n",
    "    plt.xlabel('Probability (%)')\n",
    "    plt.title('Class Probabilities from K-Fold Ensemble')\n",
    "    \n",
    "    # Add probability values\n",
    "    for i, v in enumerate(sorted_probs):\n",
    "        plt.text(v + 1, i, f\"{v:.1f}%\", va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return detailed results\n",
    "    class_probabilities = {class_names[i]: probabilities[i].item() * 100 for i in range(len(class_names))}\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': class_name,\n",
    "        'confidence': probability,\n",
    "        'all_probabilities': class_probabilities\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "ensemble, ensemble_info = load_kfold_ensemble()\n",
    "result = predict_with_ensemble(ensemble, 'path/to/your/image.jpg', ensemble_info)\n",
    "print(f\"Ensemble Prediction: {result['predicted_class']} with {result['confidence']:.1f}% confidence\")\n",
    "print(\"\\nAll class probabilities:\")\n",
    "sorted_probs = dict(sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True))\n",
    "for cls, prob in sorted_probs.items():\n",
    "    print(f\"  {cls}: {prob:.2f}%\")\n",
    "            \"\"\"\n",
    "            \n",
    "            with open('use_kfold_ensemble_model.py', 'w') as f:\n",
    "                f.write(usage_code)\n",
    "            \n",
    "            print(\"K-fold ensemble usage code saved to use_kfold_ensemble_model.py\")\n",
    "            \n",
    "        print(\"\\nK-fold cross-validation complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error in k-fold cross-validation: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if CONFIG.get('run_kfold', True):\n",
    "        main_kfold()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
